# Example Demo Steps
This is a list of steps to take to run a standard demo.

1. **Sections**
    1. Briefly explain import and how it connects to Canvas automatically.
    2. Import again to show process.
    3. Show that the sections are imported too.
    4. Any group sets you have on Canvas will be imported too, mention this becomes more important later.
2. **Students**
    1. You can view students in your course here.
    2. Note that students can be viewed along with their associated teams once those have been created.
3. **Attributes**
    1. Explain what an attribute is.
    2. Look at attributes.
        1. Personality.
        2. Project/Friends/Enemies Preferences.
        > Avoid Gender here, as the assigning of values to gender labels is a bit confusing.
    3. Explain attribute bank.
        1. Scroll through list.
4. **Projects**
    1. Explain context for projects (i.e. Capstone).
    2. Look at an unused project set or create one.
        1. Look at or create a project.
        2. Add some requirements with explanations (e.g. timeslot availability in Xpm - Ypm).
5. **Surveys**
    1. Explain how surveys are created from attributes.
    2. Explain what publishing is and do it.
    3. Go to link (either the one you just published or a pre-made one) and preview quiz on Canvas.
        > In the tfdemo (91717) course, the "Background Survey" link to Canvas is broken because the associated Canvas Quiz was deleted, so don't use this to demonstrate the previewing in Canvas functionality. With that said, the "Background Survey" currently contains random responses for all students in the course, so it should still be used when demonstrating the team generation process.
    4. Explain pulling responses.
        1. We’d have to wait for students to submit this, but we have another that’s already filled out with
           randomized data to show you the next steps.
6. **Teams**
    1. Explain team generation.
        1. Explain feature to select only some course sections to generate teams from.
        2. Select survey to make teams based on its responses.
        3. Select weight algorithm and explain options (mention random algorithm briefly).
            1. Optionally generate teams assigned to projects.
            2. Toggle friend/enemy options
            3. Diversity options (with representative examples like Gender & Timeslot Availability)
    2. We have a set of teams we’ve already generated.
        1. Take a look at a team generated with WeightAlgorithm with every bank attribute and all students.
        2. Explain visualizations and go through examples.
        3. Explain ability to move people between teams and bulk save at the end.
        4. Explain need for monitoring team performance in the course.
        5. Show monitor teams. (Remember that you can click and drag in the graphs to focus on one segment and double
           click to return to the entire graph).
7. **Peer Evaluations**
    1. Similar to attributes and surveys, we create peer evaluation attributes to place within peer evaluations.
    2. Explain options to configure feedback visibility in peer evaluation settings.
    3. To further explore the data after students complete peer evaluations, we’ll move to the deployed version of the application.
    4. Show summary data for MCQ.
        1. Export as CSV and show.
    5. Show view results as a student.
    6. Go back to /teams and show how to regenerate with peer eval data.
        1. Explain that teams can be locked (so they don't change during regeneration) and how to do that.
